{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74dd7aca-c2c5-4373-a8ef-12ffb1020cd2",
   "metadata": {},
   "source": [
    "# Extracting data from cotributors in DataCamp Blog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87705322-ab42-4e7a-bf7a-1a651edd3577",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f428da9-5ad1-4333-bf82-a6650408334a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c549eaf-1389-489a-9455-973efebd9201",
   "metadata": {},
   "source": [
    "## Creating functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28eff69e-ef25-4c0d-ad2c-7435abc54773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_last_page(article_type):\n",
    "\n",
    "    \"\"\"\n",
    "    Function to automatically detect last page of contents in DataCamp blog\n",
    "\n",
    "    Parameters:\n",
    "    - article_type: either blog page or tutorial page\n",
    "    \"\"\"\n",
    "    \n",
    "    if article_type == 'blog':\n",
    "    \n",
    "        url = \"https://www.datacamp.com/blog/\"\n",
    "        webdriver.get(url)\n",
    "        time.sleep(2)\n",
    "        soup = BeautifulSoup(webdriver.page_source, 'html.parser')\n",
    "        last_page = soup.find_all('a', class_='css-1bpjjjp')[-1].text\n",
    "        \n",
    "    elif article_type == 'tutorial':\n",
    "        url = \"https://www.datacamp.com/tutorial/\"\n",
    "        webdriver.get(url)\n",
    "        time.sleep(2)\n",
    "        soup = BeautifulSoup(webdriver.page_source, 'html.parser')\n",
    "        last_page = soup.find_all('a', class_='css-1bpjjjp')[-1].text\n",
    "    \n",
    "    return int(last_page) \n",
    "\n",
    "\n",
    "def datacamp_scraping(writer, article_type):\n",
    "    \n",
    "    \"\"\"\n",
    "    Scrap articles from a DataCamp contributor in DataCamp's Official Blog\n",
    "\n",
    "    Arguments:\n",
    "    - writer: name of the writer (as written in the Blog)\n",
    "    - article_type: either \"blog\" or \"tutorial\"\n",
    "    \"\"\"\n",
    "    \n",
    "    url_base='https://www.datacamp.com'\n",
    "    title = []\n",
    "    article_url = []\n",
    "    topic=[]\n",
    "    type_article = []\n",
    "    article_date = []\n",
    "    \n",
    "    if article_type == 'blog':\n",
    "        \n",
    "        last_page= find_last_page(article_type = article_type)\n",
    "        \n",
    "        for page in range (1, last_page +1):\n",
    "            \n",
    "            url = \"https://www.datacamp.com/blog/page/\" + str(page)\n",
    "            webdriver.get(url)\n",
    "            time.sleep(2)\n",
    "            soup = BeautifulSoup(webdriver.page_source, 'html.parser')\n",
    "            articles = soup.find('div', class_='css-119qrmy')\n",
    "            list_articles = articles.find_all('div', class_='css-8p022j')\n",
    "            \n",
    "            for article in list_articles:\n",
    "                author = article.find('p', class_='css-198tbf7').text.strip()\n",
    "                if author == writer:\n",
    "                    title.append(article.find('h2',class_='css-1yr1rb9').text)\n",
    "                    article_url.append(url_base + article.find('a',class_='css-yhqmm5').attrs['href'])\n",
    "                    topic.append(article.find('a', class_='css-xlmvza').text)\n",
    "                    type_article.append('blog')\n",
    "                    article_date.append(article.find('p',class_='css-xj3esj').text)\n",
    "    \n",
    "    elif article_type =='tutorial':\n",
    "\n",
    "        last_page= find_last_page(article_type = article_type)\n",
    "\n",
    "        for page in range (1, last_page +1):\n",
    "            url = \"https://www.datacamp.com/tutorial/page/\" + str(page)\n",
    "            webdriver.get(url)\n",
    "            time.sleep(3)\n",
    "            soup = BeautifulSoup(webdriver.page_source, 'html.parser')\n",
    "            articles = soup.find('div', class_='css-119qrmy')\n",
    "            list_articles = articles.find_all('div', class_='css-8p022j')\n",
    "            for article in list_articles:\n",
    "                author = article.find('p', class_='css-198tbf7').text.strip()\n",
    "                if author == writer:\n",
    "                    title.append(article.find('h2',class_='css-1yr1rb9').text)\n",
    "                    article_url.append(url_base + article.find('a',class_='css-yhqmm5').attrs['href'])\n",
    "                    topic.append(article.find('a', class_='css-xlmvza').text)\n",
    "                    type_article.append('tutorial')\n",
    "                    article_date.append(article.find('p',class_='css-xj3esj').text)\n",
    "                    \n",
    "    # Convert scrapped data into DataFrame\n",
    "    res = list(zip(title, article_url, topic, type_article, article_date))\n",
    "    df = pd.DataFrame(res, columns=['title','url','topic','type','date'])\n",
    "    df['date'] = pd.to_datetime(df.date)\n",
    "    df['url'] = df['url'].str.strip()\n",
    "    df['writer'] = writer\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47e3222-b272-41d1-a33a-2eb04dd0a7ac",
   "metadata": {},
   "source": [
    "## Run process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa922a21-02cb-4894-944f-215c674792dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run function and concat blogs and tutorials\n",
    "webdriver = webdriver.Chrome()\n",
    "datacamp_blog = datacamp_scraping(writer = 'Javier Canales Luna', article_type = 'blog')\n",
    "datacamp_tutorial = datacamp_scraping(writer = 'Javier Canales Luna', article_type = 'tutorial')\n",
    "datacamp = pd.concat([datacamp_blog, datacamp_tutorial], ignore_index=True)\n",
    "datacamp = datacamp.sort_values(by='date', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba2b150-9ecb-4bcf-b362-90b10bb9a286",
   "metadata": {},
   "outputs": [],
   "source": [
    "datacamp.to_csv('datacamp_javier_canales.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
